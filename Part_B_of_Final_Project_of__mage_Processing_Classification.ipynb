{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVi8qp88rAtvuY9JkaasDJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nirbarash88/node-js-exprees-server-react-client/blob/master/Part_B_of_Final_Project_of__mage_Processing_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUWx-9M9zmlA"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from google.colab import drive\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.flush_and_unmount()\n",
        "\n",
        "def setup_google_drive(dataset_folder=\"/content/drive/My Drive/Part_B_DataSet\"):\n",
        "    # Mount Google Drive\n",
        "    drive.mount(\"/content/drive\", force_remount=True)\n",
        "    # Define paths to train and test folders\n",
        "    train_folder = os.path.join(dataset_folder, \"train\")\n",
        "    test_folder = os.path.join(dataset_folder, \"test\")\n",
        "\n",
        "    return train_folder, test_folder\n",
        "\n",
        "# Example usage\n",
        "train_folder, test_folder = setup_google_drive()\n",
        "print(\"Train folder:\", train_folder)\n",
        "print(\"Test folder:\", test_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg3dXR-Azn9P",
        "outputId": "60039c4b-bff0-41c7-ed9d-c544e0b2ff2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Train folder: /content/drive/My Drive/Part_B_DataSet/train\n",
            "Test folder: /content/drive/My Drive/Part_B_DataSet/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import os\n",
        "\n",
        "class Metadata:\n",
        "    def __init__(self, shapes, line):\n",
        "        self.shapes = shapes\n",
        "        self.line = line\n",
        "\n",
        "    def __iter__(self):\n",
        "        # Iterate over the shapes attribute\n",
        "        return iter(self.shapes)\n",
        "\n",
        "def parse_metadata(metadata_text):\n",
        "    # Extract shape metadata\n",
        "    shape_metadata = metadata_text['shape_metadata']\n",
        "    line_metadata = metadata_text['line_metadata']\n",
        "\n",
        "    # Create a Metadata object\n",
        "    parsed_metadata = Metadata(shape_metadata, line_metadata)\n",
        "\n",
        "    return parsed_metadata\n",
        "\n",
        "def load_metadata(dataset_folder, num_images):\n",
        "    \"\"\"\n",
        "    Load metadata for each image from the .txt files.\n",
        "\n",
        "    Args:\n",
        "    - dataset_folder (str): Path to the dataset folder.\n",
        "    - num_images (int): Total number of images in the dataset.\n",
        "\n",
        "    Returns:\n",
        "    - list: List containing Metadata objects for each image.\n",
        "    \"\"\"\n",
        "    metadata = []\n",
        "    for i in range(num_images):\n",
        "        # Load metadata from the corresponding .txt file\n",
        "        txt_filename = f\"{i}.jpg.txt\"\n",
        "        txt_filepath = os.path.join(dataset_folder, txt_filename)\n",
        "        with open(txt_filepath, \"r\") as f:\n",
        "            metadata_text = ast.literal_eval(f.read())\n",
        "            metadata.append(parse_metadata(metadata_text))\n",
        "    return metadata\n",
        "\n",
        "num_images = 5600\n",
        "metadata = load_metadata(train_folder, num_images)\n"
      ],
      "metadata": {
        "id": "hhysi_WSzsYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Metadata example Metadata objects:\")\n",
        "print(metadata[0].shapes)\n",
        "print(metadata[0].line)\n",
        "print(\"Amount of metadata objects:\")\n",
        "print(len(metadata))\n"
      ],
      "metadata": {
        "id": "jqlxoMhdzs44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e81968-8a7a-4a4c-d0df-d89957092fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata example Metadata objects:\n",
            "[{'shape_type': 'trapezoid', 'color': 108, 'size': 19, 'position': [80, 53]}, {'shape_type': 'triangle', 'color': 86, 'size': 27, 'position': [92, 96]}, {'shape_type': 'triangle', 'color': 90, 'size': 30, 'position': [50, 53]}, {'shape_type': 'triangle', 'color': 51, 'size': 15, 'position': [112, 101]}, {'shape_type': 'trapezoid', 'color': 107, 'size': 14, 'position': [102, 111]}]\n",
            "{'shape_type': 'line', 'color': 11, 'a': 0.9, 'b': -37.400000000000006}\n",
            "Amount of metadata objects:\n",
            "5600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    # Resize the image to 128x128 -- image was generated 128X128 but never the less\n",
        "    image = cv2.resize(image, (128, 128))\n",
        "    # Normalize the image\n",
        "    image = image / 255.0\n",
        "    return image\n",
        "\n",
        "def get_label(metadata):\n",
        "    # Check if shapes length is 1 and shape is not a circle\n",
        "    if len(metadata.shapes) == 1 and metadata.shapes[0]['shape_type'] != 'circle':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def create_data_tuples(image_directory, metadata_objects):\n",
        "    data_tuples = []\n",
        "    for i, metadata in enumerate(metadata_objects):\n",
        "        # Construct the image filename\n",
        "        image_filename = f\"{i}.jpg\"\n",
        "        image_path = os.path.join(image_directory, image_filename)\n",
        "        # Check if the image file exists\n",
        "        if os.path.exists(image_path):\n",
        "            # Load and preprocess the image\n",
        "            image = process_image(image_path)\n",
        "            # Get the label\n",
        "            label = get_label(metadata)\n",
        "            # Append the tuple (image, metadata, label) to the data list\n",
        "            data_tuples.append((image, metadata, label))\n",
        "    return data_tuples\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "image_directory = train_folder\n",
        "metadata_objects = metadata  # List of metadata objects\n",
        "\n",
        "# Generate data tuples\n",
        "data_tuples = create_data_tuples(image_directory, metadata_objects)\n",
        "\n",
        "# Example of accessing the first data tuple\n",
        "image, metadata, label = data_tuples[0]\n",
        "print(\"Image size:\", image.shape)\n",
        "print(\"Label:\", label)"
      ],
      "metadata": {
        "id": "gKpn_wGLzxK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2644540-5d5c-4b6c-b2b2-ed1b03b1a0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: (128, 128)\n",
            "Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define your neural network architecture\n",
        "def create_model():\n",
        "    # Image input\n",
        "    image_input = layers.Input(shape=(128, 128, 1))\n",
        "    # Metadata input\n",
        "    metadata_input = layers.Input(shape=(len(metadata_features)+1,))\n",
        "\n",
        "    # Image processing layers\n",
        "    conv1 = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "    maxpool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
        "    conv2 = layers.Conv2D(64, (3, 3), activation='relu')(maxpool1)\n",
        "    maxpool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
        "    flatten1 = layers.Flatten()(maxpool2)\n",
        "\n",
        "    # Concatenate image and metadata features\n",
        "    concat = layers.concatenate([flatten1, metadata_input])\n",
        "\n",
        "    # Dense layers for classification\n",
        "    dense1 = layers.Dense(64, activation='relu')(concat)\n",
        "    output = layers.Dense(1, activation='sigmoid')(dense1)\n",
        "\n",
        "    model = models.Model(inputs=[image_input, metadata_input], outputs=output)\n",
        "    return model\n",
        "\n",
        "# train_data: list of tuples (image, metadata, label)\n",
        "train_data = data_tuples\n",
        "# test_data: list of tuples (image, metadata, label)\n",
        "metadata_objects_test = load_metadata(test_folder, 1400)\n",
        "test_data = create_data_tuples(test_folder, metadata_objects_test)"
      ],
      "metadata": {
        "id": "_mhSooZEzz04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define metadata features\n",
        "metadata_features = ['color', 'size', 'position']\n",
        "\n",
        "# Extract features and labels from train and test data\n",
        "def extract_features(metadata):\n",
        "    if metadata.shapes:  # Check if shapes list is not empty\n",
        "        # Extract numerical features from metadata\n",
        "        color = metadata.shapes[0]['color']\n",
        "        size = metadata.shapes[0]['size']\n",
        "        position_x, position_y = metadata.shapes[0]['position']\n",
        "        # Return extracted features as a list\n",
        "        return [color, size, position_x, position_y]\n",
        "    else:\n",
        "        return [0, 0, 0, 0]  # Return default values\n",
        "\n",
        "\n",
        "X_train_images = np.array([data[0] for data in train_data])\n",
        "X_train_metadata = np.array([extract_features(data[1]) for data in train_data])  # Assuming a function extract_features() extracts numerical features from Metadata\n",
        "y_train_labels = np.array([data[2] for data in train_data])\n",
        "\n",
        "X_test_images = np.array([data[0] for data in test_data])\n",
        "X_test_metadata = np.array([extract_features(data[1]) for data in test_data])  # Assuming a function extract_features() extracts numerical features from Metadata\n",
        "y_test_labels = np.array([data[2] for data in test_data])\n",
        "\n",
        "# Normalize image data\n",
        "X_train_images = X_train_images / 255.0\n",
        "X_test_images = X_test_images / 255.0\n",
        "\n",
        "\n",
        "# Define your model\n",
        "model = create_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit([X_train_images, X_train_metadata], y_train_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "loss, accuracy = model.evaluate([X_test_images, X_test_metadata], y_test_labels)\n",
        "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "aobBuWs6z2iF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06eb6585-1842-4f6e-e7c8-6d2a0c89d050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "140/140 [==============================] - 123s 864ms/step - loss: 0.3216 - accuracy: 0.9047 - val_loss: 0.2999 - val_accuracy: 0.9071\n",
            "Epoch 2/10\n",
            "140/140 [==============================] - 112s 803ms/step - loss: 0.2520 - accuracy: 0.9036 - val_loss: 0.1795 - val_accuracy: 0.9187\n",
            "Epoch 3/10\n",
            "140/140 [==============================] - 107s 766ms/step - loss: 0.1874 - accuracy: 0.9194 - val_loss: 0.1514 - val_accuracy: 0.9420\n",
            "Epoch 4/10\n",
            "140/140 [==============================] - 104s 746ms/step - loss: 0.1830 - accuracy: 0.9192 - val_loss: 0.1487 - val_accuracy: 0.9214\n",
            "Epoch 5/10\n",
            "140/140 [==============================] - 107s 767ms/step - loss: 0.1601 - accuracy: 0.9290 - val_loss: 0.1393 - val_accuracy: 0.9411\n",
            "Epoch 6/10\n",
            "140/140 [==============================] - 108s 773ms/step - loss: 0.1535 - accuracy: 0.9326 - val_loss: 0.1405 - val_accuracy: 0.9464\n",
            "Epoch 7/10\n",
            "140/140 [==============================] - 104s 747ms/step - loss: 0.1475 - accuracy: 0.9359 - val_loss: 0.1689 - val_accuracy: 0.9152\n",
            "Epoch 8/10\n",
            "140/140 [==============================] - 108s 776ms/step - loss: 0.1481 - accuracy: 0.9371 - val_loss: 0.1479 - val_accuracy: 0.9375\n",
            "Epoch 9/10\n",
            "140/140 [==============================] - 100s 717ms/step - loss: 0.1394 - accuracy: 0.9413 - val_loss: 0.1563 - val_accuracy: 0.9268\n",
            "Epoch 10/10\n",
            "140/140 [==============================] - 107s 762ms/step - loss: 0.1427 - accuracy: 0.9384 - val_loss: 0.1417 - val_accuracy: 0.9295\n",
            "44/44 [==============================] - 9s 207ms/step - loss: 0.1464 - accuracy: 0.9336\n",
            "Test Loss: 0.14640355110168457, Test Accuracy: 0.933571457862854\n"
          ]
        }
      ]
    }
  ]
}